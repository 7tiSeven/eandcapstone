{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Assisted Tax Audit & Research Copilot (Enhanced)\n",
    "\n",
    "This notebook demonstrates an **AI-assisted tax research and audit support system** designed to help tax auditors and regulatory authorities work faster, more consistently, and with higher confidence.\n",
    "\n",
    "## Enhanced Features\n",
    "- **Hybrid Retrieval**: Local document search (FAISS) + Live web search (Tavily)\n",
    "- **Context Understanding**: Automatic classification of tax area, request type, and detail level\n",
    "- **Relevance Filtering**: LLM-based filtering to remove irrelevant/outdated sources\n",
    "- **LangGraph Orchestration**: Structured workflow with state management\n",
    "- **Iterative Refinement**: Build on previous queries with constraints\n",
    "- **Batch Processing**: Process multiple queries at once\n",
    "\n",
    "The system allows auditors to:\n",
    "- Ask tax-related questions or describe audit scenarios in natural language\n",
    "- Automatically retrieve relevant tax laws from local docs AND official UAE sources\n",
    "- Receive a **structured, audit-ready summary** with clear citations to source documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "Tax auditors and regulatory authorities must work with a **large and continuously evolving body of tax laws, executive regulations, and official guidance**.\n",
    "\n",
    "Today, this information is:\n",
    "- Spread across multiple documents and formats\n",
    "- Frequently updated through amendments and clarifications\n",
    "- Often searched and summarized manually\n",
    "\n",
    "As a result:\n",
    "- Auditors spend significant time locating relevant provisions\n",
    "- There is a higher risk of missing applicable rules or using outdated guidance\n",
    "- Scaling audit quality across teams becomes difficult\n",
    "\n",
    "This creates a clear need for an **automated assistance system** that supports auditors with fast, reliable, and transparent access to tax information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Dependencies (Enhanced)\n",
    "!pip -q install --upgrade \\\n",
    "  openai==1.66.3 \\\n",
    "  langchain>=1.0.0 \\\n",
    "  langchain-core>=1.0.0 \\\n",
    "  langchain-openai>=0.3.0 \\\n",
    "  langchain-community>=0.3.0 \\\n",
    "  langgraph>=0.2.0 \\\n",
    "  tavily-python \\\n",
    "  faiss-cpu \\\n",
    "  sentence-transformers \\\n",
    "  pypdf \\\n",
    "  python-docx \\\n",
    "  gradio \\\n",
    "  pandas \\\n",
    "  reportlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secure Model Access\n",
    "\n",
    "The system uses a secured, OpenAI-compatible gateway.  \n",
    "Credentials are loaded from Colab Secrets and are never hard-coded.\n",
    "\n",
    "**Required Secrets:**\n",
    "- `OPEN_AI_API` - OpenAI API key\n",
    "- `TAVILY_API_KEY` - Tavily API key for web search (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Credentials Setup (Enhanced with Tavily)\n",
    "from google.colab import userdata\n",
    "\n",
    "# OpenAI API\n",
    "API_KEY = userdata.get(\"OPEN_AI_API\")\n",
    "assert API_KEY, \"Missing Colab Secret: OPEN_AI_API\"\n",
    "BASE_URL = \"https://aibe.mygreatlearning.com/openai/v1\"\n",
    "print(\"OpenAI key loaded and gateway set:\", BASE_URL)\n",
    "\n",
    "# Tavily API (optional - graceful degradation if missing)\n",
    "try:\n",
    "    TAVILY_API_KEY = userdata.get(\"TAVILY_API_KEY\")\n",
    "    if TAVILY_API_KEY:\n",
    "        print(\"Tavily API key loaded - web search enabled\")\n",
    "    else:\n",
    "        TAVILY_API_KEY = None\n",
    "        print(\"TAVILY_API_KEY not set - web search disabled (local docs only)\")\n",
    "except Exception:\n",
    "    TAVILY_API_KEY = None\n",
    "    print(\"Tavily API key not found - web search disabled (local docs only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Core Imports\n",
    "import os, io, re, json, traceback\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import date, datetime\n",
    "from enum import Enum\n",
    "\n",
    "from pypdf import PdfReader\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach Overview (Enhanced)\n",
    "\n",
    "The prototype follows a **hybrid retrieval approach** to audit support.\n",
    "\n",
    "The enhanced workflow:\n",
    "1. **Input Handling**: Structured query state with optional context (taxpayer type, sector, constraints)\n",
    "2. **Context Understanding**: Single-agent interprets tax area, request type, detail level\n",
    "3. **Hybrid Retrieval**: Local FAISS + Tavily web search for official UAE sources\n",
    "4. **Relevance Filtering**: LLM-based filter removes irrelevant/outdated results\n",
    "5. **Structured Summary**: Audit-ready memo with citations\n",
    "6. **Iterative Refinement**: User can refine previous answers\n",
    "\n",
    "```\n",
    "WORKFLOW DIAGRAM:\n",
    "+----------+    +---------------------+    +-----------+    +-----------+    +---------+\n",
    "|  Input   |--->| Context Understanding|--->| Retrieval |--->| Filtering |--->| Summary |\n",
    "+----------+    +---------------------+    +-----------+    +-----------+    +---------+\n",
    "                                                 |                              \n",
    "                                           +-----+-----+                        \n",
    "                                           |           |                        \n",
    "                                      +----+----+ +----+----+                   \n",
    "                                      |  Local  | |   Web   |                   \n",
    "                                      | (FAISS) | | (Tavily)|                   \n",
    "                                      +---------+ +---------+                   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - Structured State Objects (NEW)\n",
    "\n",
    "class TaxArea(str, Enum):\n",
    "    VAT = \"VAT\"\n",
    "    CORPORATE_TAX = \"Corporate Tax\"\n",
    "    EXCISE_TAX = \"Excise Tax\"\n",
    "    TRANSFER_PRICING = \"Transfer Pricing\"\n",
    "    CUSTOMS = \"Customs\"\n",
    "    GENERAL = \"General\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "class RequestType(str, Enum):\n",
    "    PENALTY_INQUIRY = \"penalty_inquiry\"\n",
    "    THRESHOLD_CHECK = \"threshold_check\"\n",
    "    COMPLIANCE_CHECKLIST = \"compliance_checklist\"\n",
    "    EXEMPTION_CHECK = \"exemption_check\"\n",
    "    FILING_DEADLINE = \"filing_deadline\"\n",
    "    GENERAL_RESEARCH = \"general_research\"\n",
    "\n",
    "@dataclass\n",
    "class QueryState:\n",
    "    \"\"\"Structured state object for tax queries.\"\"\"\n",
    "    query_text: str\n",
    "    tax_area: Optional[str] = None\n",
    "    request_type: Optional[str] = None\n",
    "    detail_level: str = \"standard\"  # brief, standard, comprehensive\n",
    "    taxpayer_type: Optional[str] = None  # individual, SME, large_corporate, government\n",
    "    sector: Optional[str] = None\n",
    "    as_of_date: str = field(default_factory=lambda: date.today().isoformat())\n",
    "    constraints: List[str] = field(default_factory=list)  # [\"VAT only\", \"include penalties\"]\n",
    "    enable_web_search: bool = True\n",
    "    previous_query_id: Optional[str] = None  # For refinement\n",
    "    \n",
    "    def to_prompt_context(self) -> str:\n",
    "        \"\"\"Format state for LLM prompt injection.\"\"\"\n",
    "        parts = [f\"Query: {self.query_text}\"]\n",
    "        if self.tax_area and self.tax_area != \"Auto-detect\":\n",
    "            parts.append(f\"Tax Area: {self.tax_area}\")\n",
    "        if self.taxpayer_type and self.taxpayer_type != \"Not specified\":\n",
    "            parts.append(f\"Taxpayer Type: {self.taxpayer_type}\")\n",
    "        if self.sector and self.sector != \"Not specified\":\n",
    "            parts.append(f\"Sector: {self.sector}\")\n",
    "        if self.constraints:\n",
    "            parts.append(f\"Focus Constraints: {', '.join(self.constraints)}\")\n",
    "        if self.detail_level != \"standard\":\n",
    "            parts.append(f\"Detail Level: {self.detail_level}\")\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "@dataclass\n",
    "class ContextAnalysis:\n",
    "    \"\"\"Result of context understanding step.\"\"\"\n",
    "    tax_area: str\n",
    "    request_type: str\n",
    "    detail_level: str\n",
    "    key_entities: List[str]\n",
    "    search_keywords: List[str]\n",
    "    confidence: float = 0.0\n",
    "\n",
    "@dataclass\n",
    "class UnifiedSource:\n",
    "    \"\"\"Unified source with provenance tracking.\"\"\"\n",
    "    provenance: str  # \"local\" or \"web\"\n",
    "    source_id: str   # filename or domain\n",
    "    chunk_id: str\n",
    "    content: str\n",
    "    score: float\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_citation(self) -> str:\n",
    "        \"\"\"Format for citation in output.\"\"\"\n",
    "        return f\"[{self.provenance} | {self.source_id} | {self.chunk_id}]\"\n",
    "\n",
    "print(\"State objects defined: QueryState, ContextAnalysis, UnifiedSource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - File Reading Utilities\n",
    "\n",
    "def read_file_bytes(filename: str, file_bytes: bytes) -> str:\n",
    "    name = filename.lower()\n",
    "\n",
    "    if name.endswith(\".pdf\"):\n",
    "        reader = PdfReader(io.BytesIO(file_bytes))\n",
    "        pages = []\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            txt = page.extract_text() or \"\"\n",
    "            pages.append(f\"[PAGE {i+1}] {txt}\")\n",
    "        text = \"\\n\".join(pages)\n",
    "\n",
    "    elif name.endswith(\".docx\"):\n",
    "        d = docx.Document(io.BytesIO(file_bytes))\n",
    "        text = \"\\n\".join(p.text for p in d.paragraphs)\n",
    "\n",
    "    else:\n",
    "        text = file_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Documents\n",
    "\n",
    "For demonstration purposes, the notebook generates a small set of **synthetic tax documents** inside the Colab environment.\n",
    "\n",
    "These documents simulate laws, regulations, and official guidance and are used solely to demonstrate the workflow end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Demo Document Generation\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import inch\n",
    "from pathlib import Path\n",
    "import textwrap, zipfile\n",
    "\n",
    "out_dir = Path(\"tax_demo_docs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def make_pdf(path, title, sections):\n",
    "    c = canvas.Canvas(str(path), pagesize=letter)\n",
    "    w, h = letter\n",
    "    x, y = 0.75*inch, h - 0.9*inch\n",
    "\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(x, y, title)\n",
    "    y -= 0.4*inch\n",
    "\n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    c.drawString(x, y, f\"SYNTHETIC DEMO DOCUMENT - {date.today()} (NOT REAL LAW)\")\n",
    "    y -= 0.3*inch\n",
    "\n",
    "    for header, body in sections:\n",
    "        if y < 1.2*inch:\n",
    "            c.showPage()\n",
    "            y = h - 0.9*inch\n",
    "\n",
    "        c.setFont(\"Helvetica-Bold\", 12)\n",
    "        c.drawString(x, y, header)\n",
    "        y -= 0.25*inch\n",
    "\n",
    "        c.setFont(\"Helvetica\", 11)\n",
    "        for line in textwrap.wrap(body, 95):\n",
    "            if y < 1.0*inch:\n",
    "                c.showPage()\n",
    "                y = h - 0.9*inch\n",
    "            c.drawString(x, y, line)\n",
    "            y -= 0.18*inch\n",
    "        y -= 0.15*inch\n",
    "\n",
    "    c.save()\n",
    "\n",
    "# --- Synthetic VAT Law ---\n",
    "make_pdf(\n",
    "    out_dir / \"VAT_Law_Demo.pdf\",\n",
    "    \"Synthetic VAT Law (Demo)\",\n",
    "    [\n",
    "        (\"Article 12 - Registration Threshold\",\n",
    "         \"Mandatory VAT registration applies if taxable supplies exceed AED 375,000 \"\n",
    "         \"in the preceding 12 months. Voluntary registration applies from AED 187,500.\"),\n",
    "        (\"Article 22 - Filing Deadline\",\n",
    "         \"VAT returns must be submitted no later than the 28th day following the end \"\n",
    "         \"of the tax period.\"),\n",
    "        (\"Article 59 - Late Filing Penalty\",\n",
    "         \"AED 1,000 for the first late return. AED 2,000 for repeated late returns \"\n",
    "         \"within 24 months.\"),\n",
    "        (\"Article 60 - Late Payment Penalty\",\n",
    "         \"2% immediately after the due date, 4% after 7 days, plus 1% daily thereafter.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Synthetic Regulation ---\n",
    "make_pdf(\n",
    "    out_dir / \"VAT_Regulation_Demo.pdf\",\n",
    "    \"Synthetic VAT Executive Regulation (Demo)\",\n",
    "    [\n",
    "        (\"Regulation 7 - Small Business Supplies\",\n",
    "         \"Persons below the mandatory registration threshold are not required to \"\n",
    "         \"charge VAT unless voluntarily registered.\"),\n",
    "        (\"Regulation 52 - Penalty Mitigation\",\n",
    "         \"Penalties may be reduced if a justified excuse is accepted by the authority.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Synthetic Guidance ---\n",
    "make_pdf(\n",
    "    out_dir / \"VAT_Guidance_Demo.pdf\",\n",
    "    \"Synthetic Tax Authority Guidance (Demo)\",\n",
    "    [\n",
    "        (\"GN-07 - Late Filing Review\",\n",
    "         \"Auditors should verify submission timestamps and assigned tax periods.\"),\n",
    "        (\"GN-07 - Audit Checklist\",\n",
    "         \"Check filing history, payment confirmations, turnover evidence, and \"\n",
    "         \"mitigation requests.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ZIP\n",
    "zip_path = out_dir / \"tax_demo_docs.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\") as z:\n",
    "    for f in out_dir.glob(\"*.pdf\"):\n",
    "        z.write(f, f.name)\n",
    "\n",
    "print(\"Files created in Colab:\")\n",
    "for f in out_dir.iterdir():\n",
    "    print(\" -\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Vector Store Setup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=900,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"Article \", \"Section \", \". \", \" \"]\n",
    ")\n",
    "\n",
    "VECTORSTORE = None\n",
    "\n",
    "def build_index(files: List[Dict[str, Any]]) -> str:\n",
    "    global VECTORSTORE\n",
    "\n",
    "    docs = []\n",
    "    for f in files:\n",
    "        text = read_file_bytes(f[\"name\"], f[\"bytes\"])\n",
    "        if len(text) < 50:\n",
    "            print(f\"Warning: Low text extracted from {f['name']} (len={len(text)})\")\n",
    "        docs.append(Document(page_content=text, metadata={\"source\": f[\"name\"]}))\n",
    "\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    VECTORSTORE = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    return f\"Indexed {len(files)} file(s) into {len(chunks)} chunks.\"\n",
    "\n",
    "print(\"Vector store ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - LLM Setup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "# Faster/cheaper model for classification tasks\n",
    "llm_fast = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "print(\"LLM clients initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Context Understanding (NEW)\n",
    "\n",
    "CONTEXT_ANALYSIS_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a tax query classifier for UAE tax regulations. Analyze the user's tax query and return a JSON object.\n",
    "\n",
    "Return ONLY valid JSON with these exact keys:\n",
    "- tax_area: one of [\"VAT\", \"Corporate Tax\", \"Excise Tax\", \"Transfer Pricing\", \"Customs\", \"General\", \"Unknown\"]\n",
    "- request_type: one of [\"penalty_inquiry\", \"threshold_check\", \"compliance_checklist\", \"exemption_check\", \"filing_deadline\", \"general_research\"]\n",
    "- detail_level: one of [\"brief\", \"standard\", \"comprehensive\"] based on query complexity\n",
    "- key_entities: array of specific items mentioned (amounts, dates, company types, etc.)\n",
    "- search_keywords: array of 3-5 optimal search terms for retrieval (include \"UAE\" context)\n",
    "- confidence: float 0.0-1.0 indicating classification confidence\n",
    "\n",
    "Return ONLY the JSON object. No markdown, no explanation.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "def analyze_context(query_text: str, user_tax_area: str = None) -> ContextAnalysis:\n",
    "    \"\"\"Pre-retrieval classification step.\"\"\"\n",
    "    try:\n",
    "        msg = CONTEXT_ANALYSIS_PROMPT.format_messages(query=query_text)\n",
    "        response = llm_fast.invoke(msg).content\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = json.loads(response.strip())\n",
    "        \n",
    "        # Override with user selection if provided\n",
    "        if user_tax_area and user_tax_area not in [\"Auto-detect\", \"Auto\", None, \"\"]:\n",
    "            data[\"tax_area\"] = user_tax_area\n",
    "        \n",
    "        return ContextAnalysis(\n",
    "            tax_area=data.get(\"tax_area\", \"Unknown\"),\n",
    "            request_type=data.get(\"request_type\", \"general_research\"),\n",
    "            detail_level=data.get(\"detail_level\", \"standard\"),\n",
    "            key_entities=data.get(\"key_entities\", []),\n",
    "            search_keywords=data.get(\"search_keywords\", [query_text]),\n",
    "            confidence=data.get(\"confidence\", 0.5)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Context analysis fallback: {e}\")\n",
    "        # Fallback to defaults\n",
    "        return ContextAnalysis(\n",
    "            tax_area=user_tax_area if user_tax_area and user_tax_area != \"Auto-detect\" else \"Unknown\",\n",
    "            request_type=\"general_research\",\n",
    "            detail_level=\"standard\",\n",
    "            key_entities=[],\n",
    "            search_keywords=[query_text],\n",
    "            confidence=0.0\n",
    "        )\n",
    "\n",
    "print(\"Context understanding ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Tavily Web Search Integration (NEW)\n",
    "\n",
    "# Official UAE tax source domains (whitelist for prioritization)\n",
    "TRUSTED_DOMAINS = [\n",
    "    \"tax.gov.ae\",           # Federal Tax Authority\n",
    "    \"mof.gov.ae\",           # Ministry of Finance\n",
    "    \"economy.ae\",           # Ministry of Economy\n",
    "    \"government.ae\",        # UAE Government Portal\n",
    "    \"u.ae\",                 # Official UAE portal\n",
    "    \"gcc-sg.org\",           # GCC Secretariat\n",
    "]\n",
    "\n",
    "# Extended trusted sources (authoritative commentary)\n",
    "EXTENDED_TRUSTED = TRUSTED_DOMAINS + [\n",
    "    \"pwc.com\",\n",
    "    \"ey.com\", \n",
    "    \"kpmg.com\",\n",
    "    \"deloitte.com\",\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class WebSearchResult:\n",
    "    \"\"\"Web search result structure.\"\"\"\n",
    "    url: str\n",
    "    domain: str\n",
    "    title: str\n",
    "    snippet: str\n",
    "    score: float\n",
    "    published_date: Optional[str] = None\n",
    "    is_official: bool = False\n",
    "\n",
    "def search_web_tavily(query: str, max_results: int = 5, context: ContextAnalysis = None) -> List[WebSearchResult]:\n",
    "    \"\"\"\n",
    "    Search web for UAE tax information using Tavily.\n",
    "    Prioritizes official/trusted sources.\n",
    "    \"\"\"\n",
    "    if not TAVILY_API_KEY:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        from tavily import TavilyClient\n",
    "        client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "        \n",
    "        # Build enhanced query with context\n",
    "        enhanced_query = f\"UAE {query}\"\n",
    "        if context and context.tax_area not in [\"Unknown\", \"General\"]:\n",
    "            enhanced_query = f\"UAE {context.tax_area} {query}\"\n",
    "        \n",
    "        response = client.search(\n",
    "            query=enhanced_query,\n",
    "            search_depth=\"advanced\",\n",
    "            max_results=max_results * 2,  # Fetch more, filter later\n",
    "            include_answer=False,\n",
    "            include_raw_content=False,\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for item in response.get(\"results\", []):\n",
    "            url = item.get(\"url\", \"\")\n",
    "            domain = \"\"\n",
    "            try:\n",
    "                from urllib.parse import urlparse\n",
    "                domain = urlparse(url).netloc.replace(\"www.\", \"\")\n",
    "            except:\n",
    "                domain = url.split(\"/\")[2] if len(url.split(\"/\")) > 2 else url\n",
    "            \n",
    "            # Check if official source\n",
    "            is_official = any(d in domain for d in TRUSTED_DOMAINS)\n",
    "            is_trusted = any(d in domain for d in EXTENDED_TRUSTED)\n",
    "            \n",
    "            # Score adjustment based on source authority\n",
    "            base_score = item.get(\"score\", 0.5)\n",
    "            if is_official:\n",
    "                adjusted_score = min(base_score * 1.4, 1.0)  # 40% boost for official\n",
    "            elif is_trusted:\n",
    "                adjusted_score = min(base_score * 1.2, 1.0)  # 20% boost for trusted\n",
    "            else:\n",
    "                adjusted_score = base_score * 0.8  # 20% penalty for unknown\n",
    "            \n",
    "            results.append(WebSearchResult(\n",
    "                url=url,\n",
    "                domain=domain,\n",
    "                title=item.get(\"title\", \"\"),\n",
    "                snippet=item.get(\"content\", \"\")[:800],\n",
    "                score=adjusted_score,\n",
    "                published_date=item.get(\"published_date\"),\n",
    "                is_official=is_official\n",
    "            ))\n",
    "        \n",
    "        # Sort by adjusted score, prioritize official\n",
    "        results.sort(key=lambda x: (x.is_official, x.score), reverse=True)\n",
    "        return results[:max_results]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Web search error: {e}\")\n",
    "        return []\n",
    "\n",
    "print(f\"Web search configured. Tavily enabled: {TAVILY_API_KEY is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 - Hybrid Retrieval (NEW)\n",
    "\n",
    "def retrieve_local(query: str, k: int = 6) -> List[UnifiedSource]:\n",
    "    \"\"\"Retrieve from local FAISS index.\"\"\"\n",
    "    global VECTORSTORE\n",
    "    if VECTORSTORE is None:\n",
    "        return []\n",
    "    \n",
    "    results = VECTORSTORE.similarity_search_with_score(query, k=k)\n",
    "    sources = []\n",
    "    for i, (doc, score) in enumerate(results, start=1):\n",
    "        sources.append(UnifiedSource(\n",
    "            provenance=\"local\",\n",
    "            source_id=doc.metadata.get(\"source\", \"unknown\"),\n",
    "            chunk_id=f\"L{i}\",\n",
    "            content=doc.page_content[:1200],\n",
    "            score=float(score),\n",
    "            metadata={\"filename\": doc.metadata.get(\"source\")}\n",
    "        ))\n",
    "    return sources\n",
    "\n",
    "def retrieve_web(query: str, k: int = 3, context: ContextAnalysis = None) -> List[UnifiedSource]:\n",
    "    \"\"\"Retrieve from web via Tavily.\"\"\"\n",
    "    web_results = search_web_tavily(query, max_results=k, context=context)\n",
    "    sources = []\n",
    "    for i, ws in enumerate(web_results, start=1):\n",
    "        sources.append(UnifiedSource(\n",
    "            provenance=\"web\",\n",
    "            source_id=ws.domain,\n",
    "            chunk_id=f\"W{i}\",\n",
    "            content=ws.snippet,\n",
    "            score=ws.score,\n",
    "            metadata={\n",
    "                \"url\": ws.url,\n",
    "                \"title\": ws.title,\n",
    "                \"published_date\": ws.published_date,\n",
    "                \"is_official\": ws.is_official\n",
    "            }\n",
    "        ))\n",
    "    return sources\n",
    "\n",
    "def retrieve_hybrid(\n",
    "    query: str,\n",
    "    context: ContextAnalysis,\n",
    "    k_local: int = 4,\n",
    "    k_web: int = 3,\n",
    "    enable_web: bool = True\n",
    ") -> List[UnifiedSource]:\n",
    "    \"\"\"\n",
    "    Hybrid retrieval combining local FAISS and web search.\n",
    "    Returns unified source list with clear provenance.\n",
    "    \"\"\"\n",
    "    all_sources = []\n",
    "    \n",
    "    # Local retrieval\n",
    "    local_sources = retrieve_local(query, k=k_local)\n",
    "    all_sources.extend(local_sources)\n",
    "    \n",
    "    # Web retrieval (if enabled)\n",
    "    if enable_web and TAVILY_API_KEY:\n",
    "        # Use search keywords from context if available\n",
    "        search_query = query\n",
    "        if context and context.search_keywords:\n",
    "            search_query = \" \".join(context.search_keywords[:3])\n",
    "        \n",
    "        web_sources = retrieve_web(search_query, k=k_web, context=context)\n",
    "        all_sources.extend(web_sources)\n",
    "    \n",
    "    return all_sources\n",
    "\n",
    "def format_sources_for_prompt(sources: List[UnifiedSource]) -> str:\n",
    "    \"\"\"Format unified sources for LLM prompt.\"\"\"\n",
    "    blocks = []\n",
    "    for src in sources:\n",
    "        header = src.to_citation()\n",
    "        extra = \"\"\n",
    "        if src.provenance == \"web\":\n",
    "            url = src.metadata.get(\"url\", \"\")\n",
    "            title = src.metadata.get(\"title\", \"\")\n",
    "            extra = f\" | URL: {url}\" if url else \"\"\n",
    "        blocks.append(f\"SOURCE {src.chunk_id} {header}{extra} (score={src.score:.3f}):\\n{src.content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(blocks)\n",
    "\n",
    "print(\"Hybrid retrieval ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 - Relevance Filtering (NEW)\n",
    "\n",
    "RELEVANCE_FILTER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a relevance filter for UAE tax research. Given a query and a source snippet, determine if the source is relevant.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- relevant: boolean (true ONLY if source DIRECTLY addresses the query topic)\n",
    "- confidence: float 0.0-1.0\n",
    "- reason: brief explanation (max 20 words)\n",
    "- outdated: boolean (true if content appears outdated based on dates/references to old laws)\n",
    "\n",
    "Be STRICT: only mark relevant if the source directly addresses the query. Generic tax info is NOT relevant.\n",
    "Return ONLY the JSON object.\"\"\"),\n",
    "    (\"human\", \"Query: {query}\\n\\nSource [{source_id}]:\\n{content}\")\n",
    "])\n",
    "\n",
    "def filter_relevance(\n",
    "    query: str,\n",
    "    sources: List[UnifiedSource],\n",
    "    threshold: float = 0.5,\n",
    "    max_to_filter: int = 8\n",
    ") -> List[UnifiedSource]:\n",
    "    \"\"\"\n",
    "    LLM-based relevance filtering.\n",
    "    Removes sources below confidence threshold or marked outdated.\n",
    "    \"\"\"\n",
    "    if not sources:\n",
    "        return []\n",
    "    \n",
    "    # Only filter top sources to save API calls\n",
    "    sources_to_filter = sources[:max_to_filter]\n",
    "    filtered = []\n",
    "    \n",
    "    for src in sources_to_filter:\n",
    "        try:\n",
    "            msg = RELEVANCE_FILTER_PROMPT.format_messages(\n",
    "                query=query,\n",
    "                source_id=src.chunk_id,\n",
    "                content=src.content[:500]\n",
    "            )\n",
    "            response = llm_fast.invoke(msg).content\n",
    "            result = json.loads(response.strip())\n",
    "            \n",
    "            is_relevant = result.get(\"relevant\", False)\n",
    "            confidence = result.get(\"confidence\", 0)\n",
    "            is_outdated = result.get(\"outdated\", False)\n",
    "            \n",
    "            if is_relevant and confidence >= threshold and not is_outdated:\n",
    "                src.metadata[\"relevance_confidence\"] = confidence\n",
    "                src.metadata[\"relevance_reason\"] = result.get(\"reason\", \"\")\n",
    "                filtered.append(src)\n",
    "            else:\n",
    "                print(f\"  Filtered out {src.chunk_id}: relevant={is_relevant}, conf={confidence:.2f}, outdated={is_outdated}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            # On filter failure, include source (fail open)\n",
    "            print(f\"  Filter error for {src.chunk_id}, including: {e}\")\n",
    "            filtered.append(src)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "print(\"Relevance filtering ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13 - Main Prompt and Answer Generation\n",
    "\n",
    "MAIN_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI-assisted tax research and audit support assistant for UAE tax regulations.\n",
    "\n",
    "Rules (STRICT):\n",
    "- Use ONLY the provided SOURCES. Do not use outside knowledge.\n",
    "- Every factual statement MUST have a citation like [local | filename | chunk_id] or [web | domain | chunk_id].\n",
    "- If sources are insufficient, say \"INSUFFICIENT EVIDENCE\" and list what is missing.\n",
    "- Prefer official sources (tax.gov.ae, mof.gov.ae) over commentary sources.\n",
    "- If web sources conflict with local documents, note the discrepancy.\n",
    "\n",
    "Return ONLY valid JSON with these keys:\n",
    "- tax_area: string (the primary tax area addressed)\n",
    "- summary: string (plain-language summary of findings)\n",
    "- relevant_laws: array of objects {{ \"law\": string, \"citation\": string }}\n",
    "- key_provisions: array of objects {{ \"point\": string, \"citation\": string }}\n",
    "- obligations: array of objects {{ \"item\": string, \"citation\": string }}\n",
    "- exemptions: array of objects {{ \"item\": string, \"citation\": string }}\n",
    "- penalties: array of objects {{ \"item\": string, \"citation\": string }}\n",
    "- audit_checklist: array of strings\n",
    "- assumptions: array of strings\n",
    "- sources_used: array of strings (list all source citations used)\n",
    "- web_references: array of objects {{ \"title\": string, \"url\": string }} (for web sources only)\"\"\"),\n",
    "\n",
    "    (\"human\", \"\"\"AUDIT DATE (as-of): {as_of_date}\n",
    "\n",
    "QUERY CONTEXT:\n",
    "{query_context}\n",
    "\n",
    "SOURCES:\n",
    "{sources}\n",
    "\n",
    "Return ONLY JSON. No markdown. No commentary.\"\"\")\n",
    "])\n",
    "\n",
    "def _safe_json_parse(text: str) -> Tuple[Dict[str, Any], str]:\n",
    "    raw = (text or \"\").strip()\n",
    "    \n",
    "    try:\n",
    "        return json.loads(raw), raw\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Try to extract JSON if wrapped\n",
    "    start = raw.find(\"{\")\n",
    "    end = raw.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        candidate = raw[start:end+1]\n",
    "        try:\n",
    "            return json.loads(candidate), raw\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return {\"error\": \"Model returned non-JSON or invalid JSON.\", \"raw_output\": raw[:6000]}, raw\n",
    "\n",
    "def generate_answer(\n",
    "    query_state: QueryState,\n",
    "    context: ContextAnalysis,\n",
    "    sources: List[UnifiedSource]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate structured answer from filtered sources.\"\"\"\n",
    "    \n",
    "    if not sources:\n",
    "        return {\n",
    "            \"error\": \"INSUFFICIENT EVIDENCE\",\n",
    "            \"summary\": \"No relevant sources found. Please upload relevant documents or try a different query.\",\n",
    "            \"tax_area\": context.tax_area,\n",
    "            \"sources_used\": []\n",
    "        }\n",
    "    \n",
    "    sources_text = format_sources_for_prompt(sources)\n",
    "    query_context = query_state.to_prompt_context()\n",
    "    \n",
    "    try:\n",
    "        msg = MAIN_PROMPT.format_messages(\n",
    "            query_context=query_context,\n",
    "            as_of_date=query_state.as_of_date,\n",
    "            sources=sources_text\n",
    "        )\n",
    "        response = llm.invoke(msg).content\n",
    "        parsed, raw = _safe_json_parse(response)\n",
    "        \n",
    "        # Attach metadata\n",
    "        parsed[\"_context_analysis\"] = asdict(context)\n",
    "        parsed[\"_retrieved_sources\"] = [\n",
    "            {\n",
    "                \"rank\": i,\n",
    "                \"provenance\": s.provenance,\n",
    "                \"source\": s.source_id,\n",
    "                \"chunk_id\": s.chunk_id,\n",
    "                \"score\": s.score,\n",
    "                \"preview\": s.content[:350].replace(\"\\n\", \" \"),\n",
    "                \"url\": s.metadata.get(\"url\", \"\"),\n",
    "                \"is_official\": s.metadata.get(\"is_official\", False)\n",
    "            }\n",
    "            for i, s in enumerate(sources, start=1)\n",
    "        ]\n",
    "        \n",
    "        return parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"LLM call failed: {type(e).__name__}: {e}\"}\n",
    "\n",
    "print(\"Answer generation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14 - LangGraph Workflow (NEW)\n",
    "\n",
    "try:\n",
    "    from langgraph.graph import StateGraph, END\n",
    "    from typing import TypedDict\n",
    "    LANGGRAPH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGGRAPH_AVAILABLE = False\n",
    "    print(\"LangGraph not available, using fallback workflow\")\n",
    "\n",
    "if LANGGRAPH_AVAILABLE:\n",
    "    class WorkflowState(TypedDict):\n",
    "        \"\"\"LangGraph state schema.\"\"\"\n",
    "        # Inputs\n",
    "        query_state: Dict\n",
    "        enable_filtering: bool\n",
    "        \n",
    "        # Intermediate\n",
    "        context_analysis: Optional[Dict]\n",
    "        raw_sources: List[Dict]\n",
    "        filtered_sources: List[Dict]\n",
    "        \n",
    "        # Outputs  \n",
    "        response: Dict\n",
    "        error: Optional[str]\n",
    "    \n",
    "    def node_context_understanding(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Classify query and extract context.\"\"\"\n",
    "        if state.get(\"error\"):\n",
    "            return state\n",
    "        \n",
    "        qs = QueryState(**state[\"query_state\"])\n",
    "        analysis = analyze_context(qs.query_text, qs.tax_area)\n",
    "        state[\"context_analysis\"] = asdict(analysis)\n",
    "        return state\n",
    "    \n",
    "    def node_retrieval(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Hybrid retrieval: local + web.\"\"\"\n",
    "        if state.get(\"error\"):\n",
    "            return state\n",
    "        \n",
    "        qs = QueryState(**state[\"query_state\"])\n",
    "        context = ContextAnalysis(**state[\"context_analysis\"])\n",
    "        \n",
    "        sources = retrieve_hybrid(\n",
    "            qs.query_text,\n",
    "            context,\n",
    "            enable_web=qs.enable_web_search\n",
    "        )\n",
    "        state[\"raw_sources\"] = [asdict(s) for s in sources]\n",
    "        return state\n",
    "    \n",
    "    def node_filtering(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Relevance filtering.\"\"\"\n",
    "        if state.get(\"error\"):\n",
    "            return state\n",
    "        \n",
    "        qs = QueryState(**state[\"query_state\"])\n",
    "        sources = [UnifiedSource(**s) for s in state[\"raw_sources\"]]\n",
    "        \n",
    "        if state.get(\"enable_filtering\", True) and sources:\n",
    "            filtered = filter_relevance(qs.query_text, sources)\n",
    "        else:\n",
    "            filtered = sources\n",
    "        \n",
    "        state[\"filtered_sources\"] = [asdict(s) for s in filtered]\n",
    "        return state\n",
    "    \n",
    "    def node_summary(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Generate structured summary.\"\"\"\n",
    "        if state.get(\"error\"):\n",
    "            return state\n",
    "        \n",
    "        qs = QueryState(**state[\"query_state\"])\n",
    "        context = ContextAnalysis(**state[\"context_analysis\"])\n",
    "        sources = [UnifiedSource(**s) for s in state[\"filtered_sources\"]]\n",
    "        \n",
    "        response = generate_answer(qs, context, sources)\n",
    "        state[\"response\"] = response\n",
    "        return state\n",
    "    \n",
    "    # Build graph\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "    \n",
    "    workflow.add_node(\"context_understanding\", node_context_understanding)\n",
    "    workflow.add_node(\"retrieval\", node_retrieval)\n",
    "    workflow.add_node(\"filtering\", node_filtering)\n",
    "    workflow.add_node(\"summary\", node_summary)\n",
    "    \n",
    "    workflow.set_entry_point(\"context_understanding\")\n",
    "    workflow.add_edge(\"context_understanding\", \"retrieval\")\n",
    "    workflow.add_edge(\"retrieval\", \"filtering\")\n",
    "    workflow.add_edge(\"filtering\", \"summary\")\n",
    "    workflow.add_edge(\"summary\", END)\n",
    "    \n",
    "    tax_copilot_graph = workflow.compile()\n",
    "    print(\"LangGraph workflow compiled\")\n",
    "\n",
    "def run_workflow(\n",
    "    query_state: QueryState,\n",
    "    enable_filtering: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the full tax copilot workflow.\"\"\"\n",
    "    \n",
    "    if LANGGRAPH_AVAILABLE:\n",
    "        # Use LangGraph\n",
    "        initial_state = {\n",
    "            \"query_state\": asdict(query_state),\n",
    "            \"enable_filtering\": enable_filtering,\n",
    "            \"context_analysis\": None,\n",
    "            \"raw_sources\": [],\n",
    "            \"filtered_sources\": [],\n",
    "            \"response\": {},\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "        final_state = tax_copilot_graph.invoke(initial_state)\n",
    "        return final_state.get(\"response\", {\"error\": \"Workflow failed\"})\n",
    "    \n",
    "    else:\n",
    "        # Fallback: sequential execution\n",
    "        context = analyze_context(query_state.query_text, query_state.tax_area)\n",
    "        sources = retrieve_hybrid(\n",
    "            query_state.query_text,\n",
    "            context,\n",
    "            enable_web=query_state.enable_web_search\n",
    "        )\n",
    "        if enable_filtering and sources:\n",
    "            sources = filter_relevance(query_state.query_text, sources)\n",
    "        return generate_answer(query_state, context, sources)\n",
    "\n",
    "print(\"Workflow runner ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15 - Memo Formatting (Enhanced)\n",
    "\n",
    "def json_to_memo_md(result: dict) -> str:\n",
    "    if not isinstance(result, dict):\n",
    "        return \"## Error\\n\\nUnexpected result type.\"\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        tb = result.get(\"traceback\", \"\")\n",
    "        raw = result.get(\"raw_output\", \"\")\n",
    "        return (\n",
    "            \"## Error\\n\\n\"\n",
    "            f\"**{result['error']}**\\n\\n\"\n",
    "            + (f\"### Traceback\\n```text\\n{tb}\\n```\\n\" if tb else \"\")\n",
    "            + (f\"### Raw Output\\n```text\\n{raw}\\n```\\n\" if raw else \"\")\n",
    "        )\n",
    "    \n",
    "    def bullets(items, key=\"item\"):\n",
    "        if not items:\n",
    "            return \"_None found in provided sources._\"\n",
    "        out = []\n",
    "        for x in items:\n",
    "            if isinstance(x, dict):\n",
    "                text = x.get(key) or x.get(\"point\") or x.get(\"law\") or \"\"\n",
    "                cit = x.get(\"citation\", \"\")\n",
    "                out.append(f\"- {text} **{cit}**\" if cit else f\"- {text}\")\n",
    "            else:\n",
    "                out.append(f\"- {x}\")\n",
    "        return \"\\n\".join(out)\n",
    "    \n",
    "    md = []\n",
    "    md.append(\"# Audit Research Memo\")\n",
    "    md.append(\"\")\n",
    "    \n",
    "    # Tax Area\n",
    "    tax_area = result.get(\"tax_area\", \"Not specified\")\n",
    "    md.append(f\"**Tax Area:** {tax_area}\")\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Summary\")\n",
    "    md.append(result.get(\"summary\", \"_No summary returned._\"))\n",
    "    md.append(\"\")\n",
    "    \n",
    "    # Relevant Laws (NEW)\n",
    "    if result.get(\"relevant_laws\"):\n",
    "        md.append(\"## Relevant Laws & Regulations\")\n",
    "        md.append(bullets(result.get(\"relevant_laws\", []), key=\"law\"))\n",
    "        md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Key Provisions\")\n",
    "    md.append(bullets(result.get(\"key_provisions\", []), key=\"point\"))\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Obligations\")\n",
    "    md.append(bullets(result.get(\"obligations\", []), key=\"item\"))\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Exemptions / Thresholds\")\n",
    "    md.append(bullets(result.get(\"exemptions\", []), key=\"item\"))\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Penalties\")\n",
    "    md.append(bullets(result.get(\"penalties\", []), key=\"item\"))\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Audit Checklist\")\n",
    "    checklist = result.get(\"audit_checklist\", [])\n",
    "    md.append(\"\\n\".join([f\"- [ ] {x}\" for x in checklist]) if checklist else \"_None._\")\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Assumptions\")\n",
    "    assumptions = result.get(\"assumptions\", [])\n",
    "    md.append(\"\\n\".join([f\"- {x}\" for x in assumptions]) if assumptions else \"_None._\")\n",
    "    md.append(\"\")\n",
    "    \n",
    "    md.append(\"## Sources Used\")\n",
    "    srcs = result.get(\"sources_used\", [])\n",
    "    md.append(\"\\n\".join([f\"- {x}\" for x in srcs]) if srcs else \"_See Retrieved Sources panel._\")\n",
    "    \n",
    "    # Web References (NEW)\n",
    "    web_refs = result.get(\"web_references\", [])\n",
    "    if web_refs:\n",
    "        md.append(\"\")\n",
    "        md.append(\"## Web References\")\n",
    "        for ref in web_refs:\n",
    "            title = ref.get(\"title\", \"Link\")\n",
    "            url = ref.get(\"url\", \"\")\n",
    "            if url:\n",
    "                md.append(f\"- [{title}]({url})\")\n",
    "            else:\n",
    "                md.append(f\"- {title}\")\n",
    "    \n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "print(\"Memo formatting ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16 - Demo Files Loader\n",
    "\n",
    "out_dir = Path(\"tax_demo_docs\")\n",
    "\n",
    "initial_uploaded_files_store = []\n",
    "if out_dir.exists():\n",
    "    for f_path in out_dir.glob(\"*.pdf\"):\n",
    "        with open(f_path, \"rb\") as f:\n",
    "            initial_uploaded_files_store.append({\"name\": f_path.name, \"bytes\": f.read()})\n",
    "\n",
    "print(f\"Demo files found: {len(initial_uploaded_files_store)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17 - Upload Handlers\n",
    "\n",
    "uploaded_files_store = []\n",
    "\n",
    "def ui_upload(files) -> str:\n",
    "    global uploaded_files_store\n",
    "    try:\n",
    "        uploaded_files_store = []\n",
    "        \n",
    "        if not files:\n",
    "            return \"No new files selected. Use demo files by clicking 'Build Index', or upload new ones.\"\n",
    "        \n",
    "        for f in files:\n",
    "            if isinstance(f, str) or hasattr(f, \"__fspath__\"):\n",
    "                file_path = os.fspath(f)\n",
    "                file_name = os.path.basename(file_path)\n",
    "                with open(file_path, \"rb\") as fp:\n",
    "                    file_bytes = fp.read()\n",
    "            elif isinstance(f, dict) and \"name\" in f and \"data\" in f:\n",
    "                file_name = f[\"name\"]\n",
    "                file_bytes = f[\"data\"]\n",
    "            elif hasattr(f, \"name\"):\n",
    "                file_path = getattr(f, \"name\")\n",
    "                file_name = os.path.basename(file_path)\n",
    "                with open(file_path, \"rb\") as fp:\n",
    "                    file_bytes = fp.read()\n",
    "            else:\n",
    "                return f\"Unsupported file object type: {type(f)}\"\n",
    "            \n",
    "            uploaded_files_store.append({\"name\": file_name, \"bytes\": file_bytes})\n",
    "        \n",
    "        return f\"Uploaded {len(uploaded_files_store)} file(s). Now click 'Build Index'.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Upload failed: {type(e).__name__}: {e}\\n{traceback.format_exc()}\"\n",
    "\n",
    "def ui_build_index() -> str:\n",
    "    global uploaded_files_store\n",
    "    \n",
    "    if not uploaded_files_store and initial_uploaded_files_store:\n",
    "        uploaded_files_store = initial_uploaded_files_store\n",
    "    \n",
    "    if not uploaded_files_store:\n",
    "        return \"No files to index. Upload PDFs or ensure demo PDFs exist.\"\n",
    "    \n",
    "    try:\n",
    "        return build_index(uploaded_files_store)\n",
    "    except Exception as e:\n",
    "        return f\"Indexing failed: {type(e).__name__}: {e}\\n{traceback.format_exc()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Audit Interface (Enhanced)\n",
    "\n",
    "The enhanced interface includes:\n",
    "- **Advanced Options**: Tax area, taxpayer type, sector, detail level\n",
    "- **Web Search Toggle**: Enable/disable Tavily web search\n",
    "- **Relevance Filtering**: Enable/disable LLM-based filtering\n",
    "- **Iterative Refinement**: Build on previous queries\n",
    "- **Batch Processing**: Process multiple queries at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18 - Enhanced Gradio UI\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# PDF Export\n",
    "def _memo_md_to_plain_lines(memo_md: str):\n",
    "    lines = []\n",
    "    for raw in (memo_md or \"\").splitlines():\n",
    "        s = raw.strip()\n",
    "        if not s:\n",
    "            lines.append(\"\")\n",
    "            continue\n",
    "        if s.startswith(\"### \"):\n",
    "            lines.append(s.replace(\"### \", \"\").upper())\n",
    "            continue\n",
    "        if s.startswith(\"## \"):\n",
    "            lines.append(s.replace(\"## \", \"\").upper())\n",
    "            continue\n",
    "        if s.startswith(\"# \"):\n",
    "            lines.append(s.replace(\"# \", \"\").upper())\n",
    "            continue\n",
    "        if s.startswith(\"- \"):\n",
    "            lines.append(\"* \" + s[2:])\n",
    "            continue\n",
    "        s = s.replace(\"**\", \"\")\n",
    "        lines.append(s)\n",
    "    return lines\n",
    "\n",
    "def export_memo_pdf(memo_md: str, filename_prefix: str = \"audit_memo\") -> str:\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.units import inch\n",
    "    \n",
    "    export_dir = \"exports\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    uid = uuid.uuid4().hex[:8]\n",
    "    pdf_path = os.path.join(export_dir, f\"{filename_prefix}_{ts}_{uid}.pdf\")\n",
    "    \n",
    "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
    "    width, height = letter\n",
    "    x = 0.75 * inch\n",
    "    y = height - 0.9 * inch\n",
    "    \n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(x, y, \"Audit Findings Memorandum\")\n",
    "    y -= 0.35 * inch\n",
    "    \n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    c.drawString(x, y, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    y -= 0.35 * inch\n",
    "    \n",
    "    c.setFont(\"Helvetica\", 11)\n",
    "    lines = _memo_md_to_plain_lines(memo_md)\n",
    "    \n",
    "    def wrap_line(line, max_chars=100):\n",
    "        if len(line) <= max_chars:\n",
    "            return [line]\n",
    "        chunks = []\n",
    "        words = line.split(\" \")\n",
    "        cur = \"\"\n",
    "        for w in words:\n",
    "            if len(cur) + len(w) + 1 <= max_chars:\n",
    "                cur = (cur + \" \" + w).strip()\n",
    "            else:\n",
    "                chunks.append(cur)\n",
    "                cur = w\n",
    "        if cur:\n",
    "            chunks.append(cur)\n",
    "        return chunks\n",
    "    \n",
    "    for line in lines:\n",
    "        if y < 0.8 * inch:\n",
    "            c.showPage()\n",
    "            y = height - 0.9 * inch\n",
    "            c.setFont(\"Helvetica\", 11)\n",
    "        \n",
    "        for wl in wrap_line(line, max_chars=100):\n",
    "            if y < 0.8 * inch:\n",
    "                c.showPage()\n",
    "                y = height - 0.9 * inch\n",
    "                c.setFont(\"Helvetica\", 11)\n",
    "            c.drawString(x, y, wl)\n",
    "            y -= 0.18 * inch\n",
    "        \n",
    "        if line == \"\":\n",
    "            y -= 0.05 * inch\n",
    "    \n",
    "    c.save()\n",
    "    return pdf_path\n",
    "\n",
    "def export_memo_markdown(memo_md: str) -> str:\n",
    "    export_dir = \"exports\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    md_path = os.path.join(export_dir, f\"audit_memo_{ts}.md\")\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(memo_md)\n",
    "    return md_path\n",
    "\n",
    "def evidence_badge(df: pd.DataFrame) -> str:\n",
    "    if df is None or df.empty:\n",
    "        return \"### Evidence strength: Low\\nNo source evidence retrieved.\"\n",
    "    \n",
    "    unique_sources = df[\"source\"].nunique()\n",
    "    total_chunks = len(df)\n",
    "    web_count = len(df[df[\"provenance\"] == \"web\"]) if \"provenance\" in df.columns else 0\n",
    "    local_count = total_chunks - web_count\n",
    "    \n",
    "    if unique_sources >= 3:\n",
    "        strength = \"High\"\n",
    "        color = \"green\"\n",
    "    elif unique_sources == 2:\n",
    "        strength = \"Medium\"\n",
    "        color = \"orange\"\n",
    "    else:\n",
    "        strength = \"Low\"\n",
    "        color = \"red\"\n",
    "    \n",
    "    return (\n",
    "        f\"### Evidence strength: {strength}\\n\"\n",
    "        f\"Evidence from {unique_sources} source(s): {local_count} local, {web_count} web \"\n",
    "        f\"({total_chunks} total excerpts).\"\n",
    "    )\n",
    "\n",
    "# Main query function\n",
    "def ui_ask(\n",
    "    query: str,\n",
    "    as_of_date: str,\n",
    "    top_k: int,\n",
    "    tax_area: str,\n",
    "    taxpayer_type: str,\n",
    "    sector: str,\n",
    "    detail_level: str,\n",
    "    constraints: List[str],\n",
    "    enable_web: bool,\n",
    "    enable_filtering: bool,\n",
    "    refine_mode: bool,\n",
    "    refinement_text: str,\n",
    "    last_state: dict\n",
    "):\n",
    "    try:\n",
    "        # Handle refinement\n",
    "        actual_query = query\n",
    "        if refine_mode and refinement_text and last_state:\n",
    "            actual_query = f\"{query}\\n\\nREFINEMENT: {refinement_text}\"\n",
    "        \n",
    "        # Build query state\n",
    "        query_state = QueryState(\n",
    "            query_text=actual_query,\n",
    "            tax_area=tax_area if tax_area != \"Auto-detect\" else None,\n",
    "            taxpayer_type=taxpayer_type if taxpayer_type != \"Not specified\" else None,\n",
    "            sector=sector if sector != \"Not specified\" else None,\n",
    "            detail_level=detail_level.lower(),\n",
    "            as_of_date=as_of_date or date.today().isoformat(),\n",
    "            constraints=list(constraints) if constraints else [],\n",
    "            enable_web_search=enable_web\n",
    "        )\n",
    "        \n",
    "        # Run workflow\n",
    "        result = run_workflow(query_state, enable_filtering=enable_filtering)\n",
    "        \n",
    "        # Format outputs\n",
    "        sources = result.get(\"_retrieved_sources\", [])\n",
    "        df = pd.DataFrame(sources) if sources else pd.DataFrame(\n",
    "            columns=[\"rank\", \"provenance\", \"source\", \"chunk_id\", \"score\", \"preview\", \"url\"]\n",
    "        )\n",
    "        \n",
    "        memo = json_to_memo_md(result)\n",
    "        badge = evidence_badge(df)\n",
    "        \n",
    "        # Context analysis info\n",
    "        ctx = result.get(\"_context_analysis\", {})\n",
    "        ctx_info = f\"Tax Area: {ctx.get('tax_area', 'N/A')} | Type: {ctx.get('request_type', 'N/A')} | Confidence: {ctx.get('confidence', 0):.0%}\"\n",
    "        \n",
    "        return (\n",
    "            json.dumps(result, indent=2, ensure_ascii=False),\n",
    "            df,\n",
    "            memo,\n",
    "            badge,\n",
    "            ctx_info,\n",
    "            result\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        err = {\n",
    "            \"error\": f\"{type(e).__name__}: {str(e)}\",\n",
    "            \"traceback\": traceback.format_exc()[:6000]\n",
    "        }\n",
    "        df = pd.DataFrame(columns=[\"rank\", \"provenance\", \"source\", \"chunk_id\", \"score\", \"preview\"])\n",
    "        memo = json_to_memo_md(err)\n",
    "        badge = \"### Evidence strength: Low\\nAn error occurred.\"\n",
    "        return json.dumps(err, indent=2), df, memo, badge, \"Error\", err\n",
    "\n",
    "def show_selected(df: pd.DataFrame, evt: gr.SelectData):\n",
    "    if df is None or df.empty:\n",
    "        return \"No sources to preview.\"\n",
    "    row = df.iloc[evt.index[0]].to_dict()\n",
    "    url_info = f\"\\nURL: {row.get('url')}\" if row.get('url') else \"\"\n",
    "    return (\n",
    "        f\"Source: {row.get('source')}\\n\"\n",
    "        f\"Chunk: {row.get('chunk_id')}\\n\"\n",
    "        f\"Provenance: {row.get('provenance', 'local')}\\n\"\n",
    "        f\"Score: {row.get('score'):.4f}\"\n",
    "        f\"{url_info}\\n\\n\"\n",
    "        f\"{row.get('preview')}\"\n",
    "    )\n",
    "\n",
    "# Demo queries\n",
    "def fill_q1():\n",
    "    return \"Late filing VAT return: what are the penalties and what small business thresholds or exemptions apply?\"\n",
    "\n",
    "def fill_q2():\n",
    "    return \"Provide an audit checklist to verify late filing and late payment, including what evidence to request.\"\n",
    "\n",
    "def fill_q3():\n",
    "    return \"What is the corporate income tax rate and what penalties apply?\"\n",
    "\n",
    "def ui_download_pdf(state_result: dict):\n",
    "    if not isinstance(state_result, dict) or not state_result:\n",
    "        raise gr.Error(\"No memo available yet. Please run a query first.\")\n",
    "    memo_md = json_to_memo_md(state_result)\n",
    "    return export_memo_pdf(memo_md)\n",
    "\n",
    "def ui_download_md(state_result: dict):\n",
    "    if not isinstance(state_result, dict) or not state_result:\n",
    "        raise gr.Error(\"No memo available yet. Please run a query first.\")\n",
    "    memo_md = json_to_memo_md(state_result)\n",
    "    return export_memo_markdown(memo_md)\n",
    "\n",
    "# Batch processing\n",
    "def process_batch(queries_text: str, enable_web: bool, enable_filtering: bool):\n",
    "    if not queries_text.strip():\n",
    "        return pd.DataFrame(columns=[\"query\", \"tax_area\", \"summary\", \"sources_count\"])\n",
    "    \n",
    "    queries = [q.strip() for q in queries_text.strip().split(\"\\n\") if q.strip()]\n",
    "    results = []\n",
    "    \n",
    "    for q in queries:\n",
    "        query_state = QueryState(\n",
    "            query_text=q,\n",
    "            enable_web_search=enable_web\n",
    "        )\n",
    "        result = run_workflow(query_state, enable_filtering=enable_filtering)\n",
    "        results.append({\n",
    "            \"query\": q[:100],\n",
    "            \"tax_area\": result.get(\"tax_area\", result.get(\"_context_analysis\", {}).get(\"tax_area\", \"\")),\n",
    "            \"summary\": result.get(\"summary\", \"\")[:200],\n",
    "            \"sources_count\": len(result.get(\"_retrieved_sources\", []))\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"UI functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19 - Launch Gradio Interface\n",
    "\n",
    "with gr.Blocks(title=\"Tax Audit Copilot (Enhanced)\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "# Tax Audit Research & Decision Support (Enhanced)\n",
    "**Workflow:** Upload PDFs -> Build Index -> Ask scenario -> Review memo + evidence -> Download\n",
    "\n",
    "**New Features:** Hybrid retrieval (local + web), context understanding, relevance filtering, iterative refinement\n",
    "\"\"\")\n",
    "    \n",
    "    state_result = gr.State({})\n",
    "    \n",
    "    with gr.Tab(\"1) Upload & Index\"):\n",
    "        uploader = gr.File(file_count=\"multiple\", label=\"Upload PDFs/DOCX/TXT\")\n",
    "        upload_status = gr.Textbox(label=\"Upload status\", interactive=False)\n",
    "        uploader.change(fn=ui_upload, inputs=uploader, outputs=upload_status)\n",
    "        \n",
    "        build_btn = gr.Button(\"Build Index\", variant=\"primary\")\n",
    "        build_status = gr.Textbox(label=\"Index status\", interactive=False)\n",
    "        build_btn.click(fn=ui_build_index, inputs=None, outputs=build_status)\n",
    "        \n",
    "        gr.Markdown(f\"\"\"\n",
    "---\n",
    "**Web Search Status:** {'Enabled (Tavily API key loaded)' if TAVILY_API_KEY else 'Disabled (add TAVILY_API_KEY to Colab Secrets)'}\n",
    "\"\"\")\n",
    "    \n",
    "    with gr.Tab(\"2) Ask\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                query = gr.Textbox(\n",
    "                    label=\"Audit question / scenario\",\n",
    "                    lines=4,\n",
    "                    placeholder=\"Example: Late filing VAT return - penalties, thresholds, exemptions...\"\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    demo_q1 = gr.Button(\"Demo: Late filing + thresholds\")\n",
    "                    demo_q2 = gr.Button(\"Demo: Audit checklist\")\n",
    "                    demo_q3 = gr.Button(\"Demo: Refusal test\")\n",
    "                \n",
    "                with gr.Accordion(\"Advanced Options\", open=False):\n",
    "                    with gr.Row():\n",
    "                        tax_area = gr.Dropdown(\n",
    "                            choices=[\"Auto-detect\", \"VAT\", \"Corporate Tax\", \"Excise Tax\", \"Transfer Pricing\", \"Customs\", \"General\"],\n",
    "                            value=\"Auto-detect\",\n",
    "                            label=\"Tax Area\"\n",
    "                        )\n",
    "                        taxpayer_type = gr.Dropdown(\n",
    "                            choices=[\"Not specified\", \"Individual\", \"SME\", \"Large Corporate\", \"Government Entity\"],\n",
    "                            value=\"Not specified\",\n",
    "                            label=\"Taxpayer Type\"\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        sector = gr.Dropdown(\n",
    "                            choices=[\"Not specified\", \"Real Estate\", \"Financial Services\", \"Manufacturing\", \"Retail\", \"Technology\", \"Healthcare\", \"Oil & Gas\"],\n",
    "                            value=\"Not specified\",\n",
    "                            label=\"Sector\"\n",
    "                        )\n",
    "                        detail_level = gr.Radio(\n",
    "                            choices=[\"Brief\", \"Standard\", \"Comprehensive\"],\n",
    "                            value=\"Standard\",\n",
    "                            label=\"Detail Level\"\n",
    "                        )\n",
    "                    \n",
    "                    constraints = gr.CheckboxGroup(\n",
    "                        choices=[\"VAT only\", \"Corporate Tax only\", \"Include penalties\", \"Include exemptions\", \"Exclude historical\"],\n",
    "                        label=\"Focus Constraints\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    as_of = gr.Textbox(label=\"As-of date\", value=\"Today\", scale=1)\n",
    "                    topk = gr.Slider(3, 10, value=6, step=1, label=\"Top-K excerpts\", scale=1)\n",
    "                \n",
    "                with gr.Row():\n",
    "                    enable_web = gr.Checkbox(\n",
    "                        value=TAVILY_API_KEY is not None,\n",
    "                        label=\"Enable Web Search\",\n",
    "                        interactive=TAVILY_API_KEY is not None\n",
    "                    )\n",
    "                    enable_filtering = gr.Checkbox(\n",
    "                        value=True,\n",
    "                        label=\"Enable Relevance Filtering\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Accordion(\"Iterative Refinement\", open=False):\n",
    "                    refine_mode = gr.Checkbox(value=False, label=\"Refine previous answer\")\n",
    "                    refinement_text = gr.Textbox(\n",
    "                        label=\"Refinement instruction\",\n",
    "                        placeholder=\"e.g., Focus on penalties only, Exclude VAT, Add more detail...\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                \n",
    "                ask_btn = gr.Button(\"Generate Audit Summary\", variant=\"primary\")\n",
    "                \n",
    "                context_info = gr.Textbox(label=\"Context Analysis\", interactive=False)\n",
    "                badge_md = gr.Markdown()\n",
    "                \n",
    "                with gr.Row():\n",
    "                    download_pdf_btn = gr.Button(\"Download PDF\")\n",
    "                    download_md_btn = gr.Button(\"Download Markdown\")\n",
    "                download_file = gr.File(label=\"Download\", interactive=False)\n",
    "            \n",
    "            with gr.Column(scale=3):\n",
    "                out_memo = gr.Markdown(label=\"Audit Findings Memorandum\")\n",
    "        \n",
    "        gr.Markdown(\"---\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                out_sources = gr.Dataframe(\n",
    "                    label=\"Source Evidence (click row to preview)\",\n",
    "                    interactive=False,\n",
    "                    wrap=True\n",
    "                )\n",
    "                selected_preview = gr.Textbox(label=\"Selected Evidence Preview\", lines=8, interactive=False)\n",
    "            \n",
    "            with gr.Column(scale=2):\n",
    "                out_json = gr.Code(label=\"Structured Output (JSON)\", language=\"json\")\n",
    "        \n",
    "        # Events\n",
    "        demo_q1.click(fill_q1, outputs=query)\n",
    "        demo_q2.click(fill_q2, outputs=query)\n",
    "        demo_q3.click(fill_q3, outputs=query)\n",
    "        \n",
    "        ask_btn.click(\n",
    "            fn=ui_ask,\n",
    "            inputs=[\n",
    "                query, as_of, topk,\n",
    "                tax_area, taxpayer_type, sector, detail_level, constraints,\n",
    "                enable_web, enable_filtering,\n",
    "                refine_mode, refinement_text, state_result\n",
    "            ],\n",
    "            outputs=[out_json, out_sources, out_memo, badge_md, context_info, state_result]\n",
    "        )\n",
    "        \n",
    "        out_sources.select(fn=show_selected, inputs=out_sources, outputs=selected_preview)\n",
    "        \n",
    "        download_pdf_btn.click(fn=ui_download_pdf, inputs=state_result, outputs=download_file)\n",
    "        download_md_btn.click(fn=ui_download_md, inputs=state_result, outputs=download_file)\n",
    "    \n",
    "    with gr.Tab(\"3) Batch Analysis\"):\n",
    "        gr.Markdown(\"\"\"\n",
    "### Batch Query Processing\n",
    "Enter multiple queries (one per line) to process them all at once.\n",
    "\"\"\")\n",
    "        \n",
    "        batch_input = gr.Textbox(\n",
    "            label=\"Queries (one per line)\",\n",
    "            lines=6,\n",
    "            placeholder=\"Query 1: What are VAT penalties?\\nQuery 2: Corporate tax rate in UAE?\\nQuery 3: Excise tax on tobacco?\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            batch_web = gr.Checkbox(value=TAVILY_API_KEY is not None, label=\"Enable Web Search\", interactive=TAVILY_API_KEY is not None)\n",
    "            batch_filter = gr.Checkbox(value=True, label=\"Enable Filtering\")\n",
    "        \n",
    "        batch_btn = gr.Button(\"Process Batch\", variant=\"primary\")\n",
    "        batch_output = gr.Dataframe(label=\"Results\", wrap=True)\n",
    "        \n",
    "        batch_btn.click(\n",
    "            fn=process_batch,\n",
    "            inputs=[batch_input, batch_web, batch_filter],\n",
    "            outputs=batch_output\n",
    "        )\n",
    "\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reflection\n",
    "\n",
    "This enhanced prototype demonstrates how retrieval-based language models can be applied responsibly in audit and regulatory contexts.\n",
    "\n",
    "### Enhancements Implemented\n",
    "\n",
    "1. **Structured Input State**: `QueryState` dataclass carrying query, tax area, taxpayer type, sector, constraints\n",
    "2. **Context Understanding**: Pre-retrieval LLM classification into tax area, request type, detail level\n",
    "3. **Tavily Web Search**: Live search of official UAE tax sources with domain prioritization\n",
    "4. **Hybrid Retrieval**: Merged local (FAISS) + web (Tavily) sources with provenance tracking\n",
    "5. **Relevance Filtering**: LLM-based filter removing irrelevant/outdated snippets\n",
    "6. **LangGraph Integration**: StateGraph workflow for orchestration\n",
    "7. **Iterative Refinement**: Refine previous answers with additional constraints\n",
    "8. **Enhanced Output**: Web references with clickable URLs, markdown export, batch mode\n",
    "\n",
    "### Key Principles Maintained\n",
    "\n",
    "- **Source-grounded**: Refuses to answer when evidence is missing\n",
    "- **Transparent**: All sources visible with clear provenance (local vs web)\n",
    "- **Audit-grade**: Citations, assumptions, and confidence indicators\n",
    "- **Secure**: No hardcoded secrets; uses Colab Secrets\n",
    "\n",
    "**Done by: Abdulla Ahmed Alaydaroos (Enhanced Version)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
